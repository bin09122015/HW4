{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 3\n",
      "1 / 3\n",
      "2 / 3\n",
      "dict_keys(['THE TRAGEDY OF ANTONY AND CLEOPATRA ACT III', 'THE TRAGEDY OF ANTONY AND CLEOPATRA ACT IV.', 'THE TRAGEDY OF ANTONY AND CLEOPATRA ACT V. ', 'ALLS WELL THAT ENDS WELL ACT I. ', 'ALLS WELL THAT ENDS WELL ACT V. ', 'ALLS WELL THAT ENDS WELL ACT IV.', 'THE SONNETS ACT1609', 'THE TRAGEDY OF ANTONY AND CLEOPATRA ACT_3|S', 'THE TRAGEDY OF ANTONY AND CLEOPATRA ACT_5|S', 'THE TRAGEDY OF ANTONY AND CLEOPATRA ACT_2|S', 'ALLS WELL THAT ENDS WELL ACT1603', 'THE TRAGEDY OF ANTONY AND CLEOPATRA ACT I. ', 'ALLS WELL THAT ENDS WELL ACT IV ', 'THE TRAGEDY OF ANTONY AND CLEOPATRA ACT_4|S', 'ALLS WELL THAT ENDS WELL ACT III', 'ALLS WELL THAT ENDS WELL ACT II.', 'THE TRAGEDY OF ANTONY AND CLEOPATRA ACT II.', 'ALLS WELL THAT ENDS WELL ACT V S', 'THE TRAGEDY OF ANTONY AND CLEOPATRA ACT1607'])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "snowball = nltk.SnowballStemmer('english')\n",
    "\n",
    "works = {}\n",
    "titles = []\n",
    "\n",
    "total = 38\n",
    "\n",
    "for i in range(total):\n",
    "    filename = str(i+1)+\".txt\"\n",
    "    file = open(filename, \"r\")\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "\n",
    "    f = open(filename, \"r\")\n",
    "    for _ in range(2):\n",
    "        next(f) \n",
    "    title = f.readline().strip('\\n')\n",
    "    f.close() \n",
    "    \n",
    "    acts = text.split('ACT')\n",
    "    \n",
    "    print (i, '/', total)\n",
    "    \n",
    "    for j in range(len(acts)):\n",
    "        act_title = title + \" ACT\" + acts[j][0:4]\n",
    "        titles.append(act_title)\n",
    "        words = nltk.tokenize.word_tokenize(acts[j])\n",
    "        \n",
    "        words_nstop = [w for w in words if w.lower() not in stopwords.words('english')]\n",
    "        words_npun = [w for w in words_nstop if w not in string.punctuation]\n",
    "        words_nstem = [snowball.stem(w) for w in words_npun]\n",
    "        \n",
    "        sents = nltk.tokenize.sent_tokenize(acts[j])\n",
    "        \n",
    "        works[act_title] = (words_nstem, sents)\n",
    "\n",
    "print (works.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('antoni', 32),\n",
       " ('cleopatra', 27),\n",
       " (\"'d\", 22),\n",
       " ('caesar', 22),\n",
       " (\"'s\", 20),\n",
       " ('thyreus', 14),\n",
       " ('thou', 13),\n",
       " ('enobarbus', 12),\n",
       " ('servant', 8),\n",
       " ('lord', 8),\n",
       " ('yet', 7),\n",
       " ('make', 7),\n",
       " ('know', 6),\n",
       " ('would', 6),\n",
       " ('shall', 6),\n",
       " ('o', 6),\n",
       " ('thi', 6),\n",
       " ('say', 6),\n",
       " ('ll', 6),\n",
       " ('let', 6),\n",
       " ('enter', 5),\n",
       " ('hand', 5),\n",
       " ('like', 5),\n",
       " ('one', 5),\n",
       " ('heart', 5),\n",
       " ('upon', 5),\n",
       " ('tell', 5),\n",
       " ('us', 5),\n",
       " ('follow', 5),\n",
       " ('euphronius', 5),\n",
       " ('thee', 4),\n",
       " ('see', 4),\n",
       " (\"n't\", 4),\n",
       " ('sword', 4),\n",
       " ('whip', 4),\n",
       " ('sir', 4),\n",
       " ('take', 4),\n",
       " (\"'t\", 4),\n",
       " ('hear', 4),\n",
       " ('may', 4),\n",
       " ('th', 4),\n",
       " ('asid', 4),\n",
       " ('exit', 4),\n",
       " ('god', 4),\n",
       " ('whipt', 4),\n",
       " ('till', 3),\n",
       " ('sinc', 3),\n",
       " ('time', 3),\n",
       " ('answer', 3),\n",
       " ('fight', 3)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "def getFreqDist(words):\n",
    "    nltk_text = nltk.Text(words)\n",
    "    \n",
    "    return FreqDist(nltk_text)\n",
    "\n",
    "getFreqDist(works['THE TRAGEDY OF ANTONY AND CLEOPATRA ACT_3|S'][0]).most_common(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n"
     ]
    }
   ],
   "source": [
    "def getCountFrequency(words, freq):\n",
    "    nltk_text = nltk.Text(words)\n",
    "    freq_dist = FreqDist(nltk_text)\n",
    "    \n",
    "    count = 0\n",
    "    for key,value in freq_dist.items():\n",
    "        if value == freq:\n",
    "            count += 1\n",
    "    \n",
    "    return count    \n",
    "\n",
    "def getHapaxLegomena(words):\n",
    "    return getCountFrequency(words, 1)\n",
    "\n",
    "print (getHapaxLegomena(works['THE TRAGEDY OF ANTONY AND CLEOPATRA ACT_3|S'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "def getDisLegomena(words):\n",
    "    return getCountFrequency(words, 2)\n",
    "\n",
    "print (getDisLegomena(works['THE TRAGEDY OF ANTONY AND CLEOPATRA ACT_3|S'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542\n"
     ]
    }
   ],
   "source": [
    "def getNumberUniqueWords(words):\n",
    "    return len(getFreqDist(words))\n",
    "\n",
    "print (getNumberUniqueWords(works['THE TRAGEDY OF ANTONY AND CLEOPATRA ACT_3|S'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6\n",
      "2 68\n",
      "3 103\n",
      "4 316\n",
      "5 153\n",
      "6 168\n",
      "7 73\n",
      "8 32\n",
      "9 45\n",
      "10 17\n",
      "11 1\n",
      "12 1\n"
     ]
    }
   ],
   "source": [
    "def getWordLengthDistribution(words):\n",
    "    result = FreqDist()\n",
    "    for w in words:        \n",
    "        result[len(w)] += 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "def printFreqDist(freq_dist):\n",
    "    for key,value in freq_dist.items():\n",
    "        print (key,value)    \n",
    "\n",
    "printFreqDist(getWordLengthDistribution(works['THE TRAGEDY OF ANTONY AND CLEOPATRA ACT_3|S'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1\n",
      "3 2\n",
      "6 2\n",
      "7 17\n",
      "8 10\n",
      "9 2\n",
      "10 27\n",
      "11 4\n",
      "12 2\n",
      "13 3\n",
      "14 4\n",
      "15 8\n",
      "16 1\n",
      "17 3\n",
      "18 4\n",
      "19 3\n",
      "20 2\n",
      "21 6\n",
      "22 3\n",
      "23 3\n",
      "24 3\n",
      "25 4\n",
      "26 1\n",
      "27 3\n",
      "28 1\n",
      "29 2\n",
      "31 2\n",
      "32 1\n",
      "33 1\n",
      "34 1\n",
      "37 1\n",
      "38 2\n",
      "39 2\n",
      "40 1\n",
      "43 2\n",
      "44 2\n",
      "45 1\n",
      "46 2\n",
      "47 2\n",
      "50 2\n",
      "51 2\n",
      "53 1\n",
      "54 2\n",
      "58 2\n",
      "60 1\n",
      "61 2\n",
      "62 1\n",
      "64 1\n",
      "65 1\n",
      "66 3\n",
      "67 1\n",
      "70 1\n",
      "71 3\n",
      "72 2\n",
      "75 1\n",
      "79 1\n",
      "80 1\n",
      "88 1\n",
      "90 4\n",
      "91 1\n",
      "94 2\n",
      "95 1\n",
      "96 1\n",
      "97 1\n",
      "98 1\n",
      "99 2\n",
      "102 1\n",
      "103 2\n",
      "108 2\n",
      "111 2\n",
      "117 1\n",
      "124 1\n",
      "125 1\n",
      "128 1\n",
      "137 1\n",
      "142 1\n",
      "144 2\n",
      "151 1\n",
      "154 1\n",
      "156 1\n",
      "157 1\n",
      "165 1\n",
      "179 1\n",
      "181 1\n",
      "182 1\n",
      "187 1\n",
      "189 1\n",
      "191 1\n",
      "195 1\n",
      "212 1\n",
      "215 1\n",
      "241 1\n"
     ]
    }
   ],
   "source": [
    "def getSentenceLengthDistribution(sents):\n",
    "    result = FreqDist()\n",
    "    for s in sents:        \n",
    "        result[len(s)] += 1\n",
    "    \n",
    "    return result   \n",
    "\n",
    "printFreqDist(getSentenceLengthDistribution(works['THE TRAGEDY OF ANTONY AND CLEOPATRA ACT_3|S'][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
